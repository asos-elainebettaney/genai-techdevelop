{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell with your Azure OpenAI, endpoint URL, and deployment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.12.0)\n",
      "Collecting keyrings.alt\n",
      "  Downloading keyrings.alt-5.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: jaraco.classes in /usr/local/python/3.10.13/lib/python3.10/site-packages (from keyrings.alt) (3.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from jaraco.classes->keyrings.alt) (10.2.0)\n",
      "Downloading keyrings.alt-5.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: keyrings.alt\n",
      "Successfully installed keyrings.alt-5.0.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install openai keyrings.alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "Yes, many Azure AI services support customer managed keys. This allows customers to have more control over the encryption keys used to protect their data and helps them meet their compliance and regulatory requirements.\n",
      "\n",
      "AI Content safey:\n",
      "('hate', {'filtered': False, 'severity': 'safe'})\n",
      "('self_harm', {'filtered': False, 'severity': 'safe'})\n",
      "('sexual', {'filtered': False, 'severity': 'safe'})\n",
      "('violence', {'filtered': False, 'severity': 'safe'})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]=\"594f098863634d7f94693bc88a650105\" # TODO copy your AZURE OPENAI KEY\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]=\"https://uksouth.api.cognitive.microsoft.com/\" # TODO copy your AZURE OPENAI ENDPOINT URL\n",
    "os.environ[\"AZURE_DEPLOYMENT_NAME\"]=\"aifashionassistant-gpt-35-1106\" # TODO copy your Azure OPENAI DEPLOYMENT NAME\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),    \n",
    "  api_version=\"2023-12-01-preview\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model= os.getenv(\"AZURE_DEPLOYMENT_NAME\"),\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}\n",
    "     ]\n",
    ")\n",
    "\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response.choices[0].message.content)\n",
    "\n",
    "print (\"AI Content safey:\")\n",
    "for safety_category, safety_diagnostic in response.choices[0].content_filter_results.items():\n",
    "    print((safety_category, safety_diagnostic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to make requests to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(client, prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_DEPLOYMENT_NAME\"),  \n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Tactics\n",
    "\n",
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "Clear and specific instructions for a model will guide it towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "```json\n",
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"book_id\": 1,\n",
      "      \"title\": \"The Midnight Garden\",\n",
      "      \"author\": \"Evelyn Harper\",\n",
      "      \"genre\": \"Fantasy\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 2,\n",
      "      \"title\": \"The Secret of Silver Lake\",\n",
      "      \"author\": \"Nathan Black\",\n",
      "      \"genre\": \"Mystery\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 3,\n",
      "      \"title\": \"Echoes of Eternity\",\n",
      "      \"author\": \"Samantha Wells\",\n",
      "      \"genre\": \"Science Fiction\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "\n",
      "AI Assistant:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Pour the hot water over the tea bag.\n",
      "Step 4 - Let the tea steep for a few minutes.\n",
      "Step 5 - Take out the tea bag.\n",
      "Step 6 - Add sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "\n",
      "AI Assistant:\n",
      "No steps provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \\\n",
    "singing. It's a beautiful day to go for a \\ \n",
    "walk in the park. The flowers are blooming, and the \\ \n",
    "trees are swaying gently in the breeze. People \\ \n",
    "are out and about, enjoying the lovely weather. \\ \n",
    "Some are having picnics, while others are playing \\ \n",
    "games or simply relaxing on the grass. It's a \\ \n",
    "perfect day to spend time outdoors and appreciate the \\ \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "<grandparent>: Resilience is like the mighty oak tree that withstands the fiercest storms, bending but never breaking. It is the ability to bounce back from adversity, to find strength in the face of challenges, and to persevere in the pursuit of your goals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "\n",
      "AI Assistant:\n",
      "1 - Jack and Jill go on a quest to fetch water, but misfortune strikes as they both tumble down a hill, yet they return home with undimmed adventurous spirits.\n",
      "\n",
      "2 - Jack et Jill partent en quête d'eau, mais le malheur frappe alors qu'ils dégringolent tous les deux d'une colline, mais ils rentrent chez eux avec des esprits aventureux indomptés.\n",
      "\n",
      "3 - Jack, Jill\n",
      "\n",
      "4 - \n",
      "{\n",
      "  \"french_summary\": \"Jack et Jill partent en quête d'eau, mais le malheur frappe alors qu'ils dégringolent tous les deux d'une colline, mais ils rentrent chez eux avec des esprits aventureux indomptés.\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "\n",
      "AI Assistant:\n",
      "Summary: Jack and Jill, siblings, go on a quest to fetch water from a hilltop well, but misfortune strikes as Jack trips on a stone and tumbles down the hill, with Jill following suit, yet they return home with comforting embraces and their adventurous spirits undimmed.\n",
      "\n",
      "Translation: Jack et Jill, frère et sœur, partent en quête d'eau d'un puits au sommet d'une colline, mais le malheur frappe lorsque Jack trébuche sur une pierre et dégringole la colline, suivi par Jill, mais ils rentrent chez eux avec des étreintes réconfortantes et leurs esprits aventureux intacts.\n",
      "\n",
      "Names: Jack, Jill\n",
      "\n",
      "Output JSON: \n",
      "{\n",
      "  \"french_summary\": \"Jack et Jill, frère et sœur, partent en quête d'eau d'un puits au sommet d'une colline, mais le malheur frappe lorsque Jack trébuche sur une pierre et dégringole la colline, suivi par Jill, mais ils rentrent chez eux avec des étreintes réconfortantes et leurs esprits aventureux intacts.\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "The student's solution is correct. The total cost for the first year of operations as a function of the number of square feet is indeed 450x + 100,000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "The total cost for the first year of operations is the sum of the land cost, solar panel cost, and maintenance cost.\n",
      "\n",
      "Total cost = Land cost + Solar panel cost + Maintenance cost\n",
      "Total cost = $100x + $250x + $100,000 + $10x\n",
      "Total cost = $360x + $100,000\n",
      "\n",
      "So the total cost for the first year of operations as a function of the number of square feet is 360x + 100,000.\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "Yes\n",
      "```\n",
      "Student grade:\n",
      "```\n",
      "correct\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Assistant:\n",
      "The AeroGlide UltraSlim Smart Toothbrush by Boie is a high-tech toothbrush designed to provide a superior cleaning experience. It features an ultra-slim design that allows for easy maneuverability and access to hard-to-reach areas of the mouth. The toothbrush also comes with smart technology that tracks brushing habits and provides real-time feedback to help improve oral hygiene.\n",
      "\n",
      "The brush head is made from soft, durable bristles that are gentle on the gums and teeth, while still effectively removing plaque and debris. The bristles are also infused with silver to help prevent bacterial growth and keep the brush clean.\n",
      "\n",
      "The AeroGlide UltraSlim Smart Toothbrush is rechargeable and comes with a long-lasting battery, making it convenient for travel and everyday use. It also connects to a smartphone app, allowing users to track their brushing habits and receive personalized recommendations for improving their oral care routine.\n",
      "\n",
      "Overall, the AeroGlide UltraSlim Smart Toothbrush by Boie offers a combination of advanced technology and thoughtful design to provide a thorough and effective cleaning experience for users.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print (\"\\nAI Assistant:\\n%s\\n\" % response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment (positive/negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the product review is positive. The customer is satisfied with the lamp, the company's customer service, and the overall experience with the product.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify types of emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy, satisfied, grateful, impressed, content\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract product and company name from customer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing multiple tasks at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Survey\n",
      "2. Job satisfaction\n",
      "3. NASA\n",
      "4. Social Security Administration\n",
      "5. Government pledge\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(client, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your dev environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting promptflow\n",
      "  Downloading promptflow-1.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting promptflow-tools\n",
      "  Downloading promptflow_tools-1.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (5.9.8)\n",
      "Requirement already satisfied: httpx>=0.25.1 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (0.26.0)\n",
      "Requirement already satisfied: openai in /usr/local/python/3.10.13/lib/python3.10/site-packages (from promptflow) (1.12.0)\n",
      "Collecting flask<4.0.0,>=2.2.3 (from promptflow)\n",
      "  Downloading flask-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=1.4.48 (from promptflow)\n",
      "  Downloading SQLAlchemy-2.0.27-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.5.3 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (2.2.0)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from promptflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting keyring<25.0.0,>=24.2.0 (from promptflow)\n",
      "  Downloading keyring-24.3.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pydash<8.0.0,>=6.0.0 (from promptflow)\n",
      "  Downloading pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cryptography<42.0.0,>=41.0.3 (from promptflow)\n",
      "  Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (0.4.6)\n",
      "Collecting tabulate<1.0.0,>=0.9.0 (from promptflow)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (3.13.1)\n",
      "Collecting marshmallow<4.0.0,>=3.5 (from promptflow)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (3.1.41)\n",
      "Collecting tiktoken>=0.4.0 (from promptflow)\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting strictyaml<2.0.0,>=1.5.0 (from promptflow)\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting waitress<3.0.0,>=2.1.2 (from promptflow)\n",
      "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencensus-ext-azure<2.0.0 (from promptflow)\n",
      "  Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from promptflow)\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pyarrow<15.0.0,>=14.0.1 (from promptflow)\n",
      "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (10.2.0)\n",
      "Collecting filetype>=1.2.0 (from promptflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from promptflow) (4.21.1)\n",
      "Collecting docutils (from promptflow)\n",
      "  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.22.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow)\n",
      "  Downloading flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting google-search-results==2.4.1 (from promptflow-tools)\n",
      "  Downloading google_search_results-2.4.1.tar.gz (11 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from google-search-results==2.4.1->promptflow-tools) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.10/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/codespace/.local/lib/python3.10/site-packages (from cryptography<42.0.0,>=41.0.3->promptflow) (1.16.0)\n",
      "Collecting Werkzeug>=3.0.0 (from flask<4.0.0,>=2.2.3->promptflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/codespace/.local/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow) (3.1.3)\n",
      "Collecting itsdangerous>=2.1.2 (from flask<4.0.0,>=2.2.3->promptflow)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3 (from flask<4.0.0,>=2.2.3->promptflow)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask<4.0.0,>=2.2.3->promptflow)\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow)\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz in /home/codespace/.local/lib/python3.10/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow) (2024.1)\n",
      "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow)\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow) (4.0.11)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow) (4.2.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow) (1.0.2)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow) (0.17.1)\n",
      "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading jaraco.classes-3.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading importlib_metadata-7.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting SecretStorage>=3.2 (from keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jeepney>=0.4.2 (from keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /home/codespace/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.5->promptflow) (23.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai->promptflow) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai->promptflow) (2.6.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai->promptflow) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai->promptflow) (4.9.0)\n",
      "Collecting azure-core<2.0.0,>=1.12.0 (from opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading azure_core-1.30.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting azure-identity<2.0.0,>=1.5.0 (from opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading azure_identity-1.15.0-py3-none-any.whl.metadata (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencensus<1.0.0,>=0.11.4 (from opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api~=1.15 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk~=1.22.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.22.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/codespace/.local/lib/python3.10/site-packages (from pandas<3.0.0,>=1.5.3->promptflow) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas<3.0.0,>=1.5.3->promptflow) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas<3.0.0,>=1.5.3->promptflow) (2023.4)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->promptflow)\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3.0.0,>=1.4.48->promptflow)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.4.0->promptflow)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m961.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio->httpx>=0.25.1->promptflow) (1.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.12.0->opencensus-ext-azure<2.0.0->promptflow) (1.16.0)\n",
      "Collecting msal<2.0.0,>=1.24.0 (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading msal-1.26.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading msal_extensions-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography<42.0.0,>=41.0.3->promptflow) (2.21)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow) (5.0.1)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow) (2.1.5)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-sdk~=1.22.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->promptflow) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->promptflow) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (2.0.7)\n",
      "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow)\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading google_auth-2.28.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting portalocker<3,>=1.0 (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->promptflow)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading promptflow-1.5.0-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading promptflow_tools-1.2.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m859.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.3/101.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keyring-24.3.0-py3-none-any.whl (38 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.22.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydash-7.0.7-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.3/110.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.27-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.30.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.15.0-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.7/164.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
      "Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading jaraco.classes-3.3.1-py3-none-any.whl (6.8 kB)\n",
      "Downloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.26.0-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.1-py3-none-any.whl size=25780 sha256=671782c62390fc3abd0dc7b754d412978985a29a9c099d265af96d57f028c12e\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/3f/f9/cf/5e4c3bbb6a77ae7f574bf5cfe7d56c6b801e50aada40df13f1\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: opencensus-context, filetype, aniso8601, zipp, wrapt, Werkzeug, waitress, tabulate, ruamel.yaml.clib, regex, python-dotenv, PyJWT, pydash, pyasn1, pyarrow, protobuf, portalocker, opentelemetry-semantic-conventions, more-itertools, marshmallow, jeepney, itsdangerous, importlib-resources, greenlet, docutils, click, cachetools, blinker, backoff, tiktoken, strictyaml, sqlalchemy, ruamel.yaml, rsa, pyasn1-modules, opentelemetry-proto, jaraco.classes, importlib-metadata, googleapis-common-protos, google-search-results, flask, deprecated, cryptography, bs4, azure-core, SecretStorage, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, opentelemetry-sdk, msal, keyring, google-api-core, flask-restx, opentelemetry-exporter-otlp-proto-http, opencensus, msal-extensions, azure-identity, opencensus-ext-azure, promptflow, promptflow-tools\n",
      "\u001b[33m  WARNING: The script filetype is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script waitress-serve is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tabulate is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script dotenv is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script docutils is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script flask is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script keyring is installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pfazure and pfs are installed in '/usr/local/python/3.10.13/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed PyJWT-2.8.0 SecretStorage-3.3.3 Werkzeug-3.0.1 aniso8601-9.0.1 azure-core-1.30.0 azure-identity-1.15.0 backoff-2.2.1 blinker-1.7.0 bs4-0.0.2 cachetools-5.3.2 click-8.1.7 cryptography-41.0.7 deprecated-1.2.14 docutils-0.20.1 filetype-1.2.0 flask-3.0.2 flask-restx-1.3.0 google-api-core-2.17.1 google-auth-2.28.1 google-search-results-2.4.1 googleapis-common-protos-1.62.0 greenlet-3.0.3 importlib-metadata-6.11.0 importlib-resources-6.1.1 itsdangerous-2.1.2 jaraco.classes-3.3.1 jeepney-0.8.0 keyring-24.3.0 marshmallow-3.20.2 more-itertools-10.2.0 msal-1.26.0 msal-extensions-1.1.0 opencensus-0.11.4 opencensus-context-0.1.3 opencensus-ext-azure-1.1.13 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-http-1.22.0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 portalocker-2.8.2 promptflow-1.5.0 promptflow-tools-1.2.0 protobuf-4.25.3 pyarrow-14.0.2 pyasn1-0.5.1 pyasn1-modules-0.3.0 pydash-7.0.7 python-dotenv-1.0.1 regex-2023.12.25 rsa-4.9 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 sqlalchemy-2.0.27 strictyaml-1.7.3 tabulate-0.9.0 tiktoken-0.6.0 waitress-2.1.2 wrapt-1.16.0 zipp-3.17.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install promptflow promptflow-tools bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promptflow\t\t\t 1.5.0\n",
      "\n",
      "Executable '/home/codespace/.python/current/bin/python'\n",
      "Python (Linux) 3.10.13 (main, Feb  6 2024, 19:53:26) [GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "!pf -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flow from scratch...\n",
      "Creating README.md...\n",
      "Creating chat.jinja2...\n",
      "Creating .promptflow folder...\n",
      "Creating /workspaces/genai-techdevelop/my_chatbot/flow.dag.yaml...\n",
      "Creating /workspaces/genai-techdevelop/my_chatbot/openai.yaml...\n",
      "Creating /workspaces/genai-techdevelop/my_chatbot/azure_openai.yaml...\n",
      "Creating /workspaces/genai-techdevelop/my_chatbot/requirements.txt...\n",
      "Creating /workspaces/genai-techdevelop/my_chatbot/.gitignore...\n",
      "Done. Created chat flow folder: /workspaces/genai-techdevelop/my_chatbot.\n",
      "The generated chat flow is requiring a connection named open_ai_connection, please follow the steps in README.md to create if you haven't done that.\n",
      "You can execute this command to test the flow, pf flow test --flow ./my_chatbot --interactive\n"
     ]
    }
   ],
   "source": [
    "!pf flow init --flow ./my_chatbot --type chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"open_ai_connection\",\n",
      "    \"module\": \"promptflow.connections\",\n",
      "    \"created_date\": \"2024-02-22T00:47:29.638666\",\n",
      "    \"last_modified_date\": \"2024-02-22T00:47:29.638666\",\n",
      "    \"type\": \"azure_open_ai\",\n",
      "    \"api_key\": \"******\",\n",
      "    \"api_base\": \"https://uksouth.api.cognitive.microsoft.com\",\n",
      "    \"api_type\": \"azure\",\n",
      "    \"api_version\": \"2023-07-01-preview\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf connection create --file ./my_chatbot/azure_openai.yaml --set api_key=\"594f098863634d7f94693bc88a650105\" --set api_base=\"https://uksouth.api.cognitive.microsoft.com\" --name open_ai_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-22 00:48:30 +0000    6730 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-02-22 00:48:30 +0000    6730 execution.flow     INFO     Start to run 1 nodes with concurrency level 16.\n",
      "2024-02-22 00:48:30 +0000    6730 execution.flow     INFO     Executing node chat. node run id: 043ee812-e566-48e1-8f7a-cb040117f409_chat_0\n",
      "2024-02-22 00:48:30 +0000    6730 execution.flow     INFO     Node chat completes.\n",
      "{\n",
      "    \"answer\": \"I'm happy to help! What would you like to see or learn about?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow test --flow ./my_chatbot --inputs question=\"show\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-22 00:49:02 +0000    6976 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-02-22 00:49:02 +0000    6976 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.\n",
      "2024-02-22 00:49:02 +0000    6976 execution.flow     INFO     Executing node extract_query_from_question. node run id: 424108c3-84de-4449-8c87-4b8f8515c305_extract_query_from_question_0\n",
      "2024-02-22 00:49:02 +0000    6976 execution.flow     INFO     Node extract_query_from_question completes.\n",
      "2024-02-22 00:49:02 +0000    6976 execution.flow     INFO     Executing node get_wiki_url. node run id: 424108c3-84de-4449-8c87-4b8f8515c305_get_wiki_url_0\n",
      "2024-02-22 00:49:03 +0000    6976 execution.flow     INFO     [get_wiki_url in line 0 (index starts from 0)] stdout> Could not find US presidential candidates 2024. Similar entity: ['2024 Democratic Party presidential candidates', '2024 Republican Party presidential primaries'].\n",
      "2024-02-22 00:49:03 +0000    6976 execution.flow     INFO     Node get_wiki_url completes.\n",
      "2024-02-22 00:49:03 +0000    6976 execution.flow     INFO     Executing node search_result_from_url. node run id: 424108c3-84de-4449-8c87-4b8f8515c305_search_result_from_url_0\n",
      "2024-02-22 00:49:04 +0000    6976 execution.flow     INFO     Node search_result_from_url completes.\n",
      "2024-02-22 00:49:04 +0000    6976 execution.flow     INFO     Executing node process_search_result. node run id: 424108c3-84de-4449-8c87-4b8f8515c305_process_search_result_0\n",
      "2024-02-22 00:49:04 +0000    6976 execution.flow     INFO     Node process_search_result completes.\n",
      "2024-02-22 00:49:04 +0000    6976 execution.flow     INFO     Executing node augmented_chat. node run id: 424108c3-84de-4449-8c87-4b8f8515c305_augmented_chat_0\n",
      "2024-02-22 00:49:07 +0000    6976 execution.flow     INFO     Node augmented_chat completes.\n",
      "{\n",
      "    \"answer\": \"As of November 2023, more than 180 candidates have filed with the Federal Election Commission to run for the Democratic nomination in 2024. However, the following candidates have received substantial major media coverage, have been elected to major public office, or have been included in at least five national polls. On the Republican side, there have been a number of candidates, including Ron DeSantis, Nikki Haley, Vivek Ramaswamy, and former President Donald Trump. Trump, the frontrunner, has maintained a consistent lead in primary polling since 2020. Following the Iowa caucuses, Ramaswamy and DeSantis dropped out of the race and endorsed Trump, leaving Trump and Haley as the only remaining major candidates.\\n\\nSOURCES:\\n- https://en.wikipedia.org/w/index.php?search=2024+Democratic+Party+presidential+candidates\\n- https://en.wikipedia.org/w/index.php?search=2024+Republican+Party+presidential+primaries\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow test --flow ./part2/chat_with_wikipedia --inputs question=\"Who is running for US president 2024?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-22 00:49:23 +0000    7139 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-02-22 00:49:23 +0000    7139 execution.flow     INFO     Start to run 2 nodes with concurrency level 16.\n",
      "2024-02-22 00:49:23 +0000    7139 execution.flow     INFO     Executing node use_functions_with_chat_models. node run id: 86352121-f7bc-4a16-9d7b-a411879d9033_use_functions_with_chat_models_0\n",
      "2024-02-22 00:49:24 +0000    7139 execution.flow     INFO     Node use_functions_with_chat_models completes.\n",
      "2024-02-22 00:49:24 +0000    7139 execution.flow     INFO     Executing node run_function. node run id: 86352121-f7bc-4a16-9d7b-a411879d9033_run_function_0\n",
      "2024-02-22 00:49:24 +0000    7139 execution.flow     INFO     [run_function in line 0 (index starts from 0)] stdout> get_current_weather\n",
      "2024-02-22 00:49:24 +0000    7139 execution.flow     INFO     [run_function in line 0 (index starts from 0)] stdout> {'location': 'Bristol'}\n",
      "2024-02-22 00:49:24 +0000    7139 execution.flow     INFO     Node run_function completes.\n",
      "{\n",
      "    \"answer\": {\n",
      "        \"location\": \"Bristol\",\n",
      "        \"temperature\": \"72\",\n",
      "        \"unit\": \"fahrenheit\",\n",
      "        \"forecast\": [\n",
      "            \"sunny\",\n",
      "            \"windy\"\n",
      "        ]\n",
      "    },\n",
      "    \"llm_output\": {\n",
      "        \"content\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\\"location\\\":\\\"Bristol\\\"}\",\n",
      "            \"name\": \"get_current_weather\"\n",
      "        },\n",
      "        \"tool_calls\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pf flow test --flow ./part2/functions --inputs question=\"What is the weather in Bristol?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
